{"id":"video-intelligence/v1beta2/doc/doc_video_intelligence","type":"class","overview":"<p>\n  This class allows you interact with Cloud Video Intelligence.\n</p>\n\n\n\n<p>\n  First, install <code>@google-cloud/video-intelligence</code> with npm:\n</p>\n\n<div hljs language=\"bash\">$ npm install --save @google-cloud/video-intelligence</div>\n\n<p>\n  If you are running your app on Google Compute Engine, you won't need to worry about supplying connection configuration options to <code>@google-cloud/video-intelligence</code>â€” we figure that out for you.\n</p>\n\n<p>\n  However, if you're running your app elsewhere, you will need to provide project details to authenticate API requests.\n</p>\n\n<h4>Google Cloud Platform</h4>\n<div hljs language=\"javascript\">\nvar video = require('@google-cloud/video-intelligence')();\n</div>\n\n<h4>Elsewhere</h4>\n<div hljs language=\"javascript\">\nvar video = require('@google-cloud/video-intelligence')({\n  projectId: 'grape-spaceship-123',\n  keyFilename: '/path/to/keyfile.json'\n});\n</div>\n\n<p>\n  The full set of options which can be passed to <code>@google-cloud/video-intelligence</code> are outlined in our <a href=\"#/docs/video-intelligence/v0.3.0/guides/authentication\">Authentication guide</a>.\n</p>\n","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js","parent":"video-intelligence","children":[],"methods":[{"id":"AnnotateVideoRequest","name":"AnnotateVideoRequest","type":"instance","description":"","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L67","resources":[],"examples":[],"params":[{"name":"inputUri","description":"<p> Input video location. Currently, only  <a href=\"https://cloud.google.com/storage/\">Google Cloud Storage</a> URIs are  supported, which must be specified in the following format:  <code>gs://bucket-id/object-id</code> (other URI formats return  {@link google.rpc.Code.INVALID_ARGUMENT}). For more information, see  <a href=\"https://cloud.google.com/storage/docs/reference-uris\">Request URIs</a>.  A video URI may include wildcards in <code>object-id</code>, and thus identify  multiple videos. Supported wildcards: &#39;*&#39; to match 0 or more characters;  &#39;?&#39; to match 1 character. If unset, the input video should be embedded  in the request as <code>input_content</code>. If set, <code>input_content</code> should be unset.</p>","types":["string"],"optional":false,"nullable":false},{"name":"inputContent","description":"<p> The video data bytes. Encoding: base64. If unset, the input video(s)  should be specified via <code>input_uri</code>. If set, <code>input_uri</code> should be unset.</p>","types":["string"],"optional":false,"nullable":false},{"name":"features","description":"<p> Requested video annotation features.</p><p> The number should be among the values of <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'Feature'\n        })\">Feature</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'Feature'\n        })\">Feature</a></p>","types":["number[]"],"optional":false,"nullable":false},{"name":"videoContext","description":"<p> Additional video context and/or feature-specific parameters.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoContext'\n        })\">VideoContext</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoContext'\n        })\">VideoContext</a></p>","types":["Object"],"optional":false,"nullable":false},{"name":"outputUri","description":"<p> Optional location where the output (in JSON format) should be stored.  Currently, only <a href=\"https://cloud.google.com/storage/\">Google Cloud Storage</a>  URIs are supported, which must be specified in the following format:  <code>gs://bucket-id/object-id</code> (other URI formats return  {@link google.rpc.Code.INVALID_ARGUMENT}). For more information, see  <a href=\"https://cloud.google.com/storage/docs/reference-uris\">Request URIs</a>.</p>","types":["string"],"optional":false,"nullable":false},{"name":"locationId","description":"<p> Optional cloud region where annotation should take place. Supported cloud  regions: <code>us-east1</code>, <code>us-west1</code>, <code>europe-west1</code>, <code>asia-east1</code>. If no region  is specified, a region will be determined based on video file location.</p>","types":["string"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"VideoContext","name":"VideoContext","type":"instance","description":"<p>Video context and/or feature-specific parameters.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L104","resources":[],"examples":[],"params":[{"name":"segments","description":"<p> Video segments to annotate. The segments may overlap and are not required  to be contiguous or span the whole video. If unspecified, each video  is treated as a single segment.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"labelDetectionConfig","description":"<p> Config for LABEL_DETECTION.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'LabelDetectionConfig'\n        })\">LabelDetectionConfig</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'LabelDetectionConfig'\n        })\">LabelDetectionConfig</a></p>","types":["Object"],"optional":false,"nullable":false},{"name":"shotChangeDetectionConfig","description":"<p> Config for SHOT_CHANGE_DETECTION.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'ShotChangeDetectionConfig'\n        })\">ShotChangeDetectionConfig</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'ShotChangeDetectionConfig'\n        })\">ShotChangeDetectionConfig</a></p>","types":["Object"],"optional":false,"nullable":false},{"name":"explicitContentDetectionConfig","description":"<p> Config for EXPLICIT_CONTENT_DETECTION.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'ExplicitContentDetectionConfig'\n        })\">ExplicitContentDetectionConfig</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'ExplicitContentDetectionConfig'\n        })\">ExplicitContentDetectionConfig</a></p>","types":["Object"],"optional":false,"nullable":false},{"name":"faceDetectionConfig","description":"<p> Config for FACE_DETECTION.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'FaceDetectionConfig'\n        })\">FaceDetectionConfig</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'FaceDetectionConfig'\n        })\">FaceDetectionConfig</a></p>","types":["Object"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"LabelDetectionConfig","name":"LabelDetectionConfig","type":"instance","description":"<p>Config for LABEL_DETECTION.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L131","resources":[],"examples":[],"params":[{"name":"labelDetectionMode","description":"<p> What labels should be detected with LABEL_DETECTION, in addition to  video-level labels or segment-level labels.  If unspecified, defaults to <code>SHOT_MODE</code>.</p><p> The number should be among the values of <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'LabelDetectionMode'\n        })\">LabelDetectionMode</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'LabelDetectionMode'\n        })\">LabelDetectionMode</a></p>","types":["number"],"optional":false,"nullable":false},{"name":"stationaryCamera","description":"<p> Whether the video has been shot from a stationary (i.e. non-moving) camera.  When set to true, might improve detection accuracy for moving objects.  Should be used with <code>SHOT_AND_FRAME_MODE</code> enabled.</p>","types":["boolean"],"optional":false,"nullable":false},{"name":"model","description":"<p> Model to use for label detection.  Supported values: &quot;builtin/stable&quot; (the default if unset) and  &quot;builtin/latest&quot;.</p>","types":["string"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"ShotChangeDetectionConfig","name":"ShotChangeDetectionConfig","type":"instance","description":"<p>Config for SHOT_CHANGE_DETECTION.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L146","resources":[],"examples":[],"params":[{"name":"model","description":"<p> Model to use for shot change detection.  Supported values: &quot;builtin/stable&quot; (the default if unset) and  &quot;builtin/latest&quot;.</p>","types":["string"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"ExplicitContentDetectionConfig","name":"ExplicitContentDetectionConfig","type":"instance","description":"<p>Config for EXPLICIT_CONTENT_DETECTION.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L161","resources":[],"examples":[],"params":[{"name":"model","description":"<p> Model to use for explicit content detection.  Supported values: &quot;builtin/stable&quot; (the default if unset) and  &quot;builtin/latest&quot;.</p>","types":["string"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"FaceDetectionConfig","name":"FaceDetectionConfig","type":"instance","description":"<p>Config for FACE_DETECTION.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L179","resources":[],"examples":[],"params":[{"name":"model","description":"<p> Model to use for face detection.  Supported values: &quot;builtin/stable&quot; (the default if unset) and  &quot;builtin/latest&quot;.</p>","types":["string"],"optional":false,"nullable":false},{"name":"includeBoundingBoxes","description":"<p> Whether bounding boxes be included in the face annotation output.</p>","types":["boolean"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"VideoSegment","name":"VideoSegment","type":"instance","description":"<p>Video segment.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L201","resources":[],"examples":[],"params":[{"name":"startTimeOffset","description":"<p> Time-offset, relative to the beginning of the video,  corresponding to the start of the segment (inclusive).</p><p> This object should have the same structure as google.protobuf.Duration</p>","types":["Object"],"optional":false,"nullable":false},{"name":"endTimeOffset","description":"<p> Time-offset, relative to the beginning of the video,  corresponding to the end of the segment (inclusive).</p><p> This object should have the same structure as google.protobuf.Duration</p>","types":["Object"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"LabelSegment","name":"LabelSegment","type":"instance","description":"<p>Video segment level annotation results for label detection.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L219","resources":[],"examples":[],"params":[{"name":"segment","description":"<p> Video segment where a label was detected.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a></p>","types":["Object"],"optional":false,"nullable":false},{"name":"confidence","description":"<p> Confidence that the label is accurate. Range: [0, 1].</p>","types":["number"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"LabelFrame","name":"LabelFrame","type":"instance","description":"<p>Video frame level annotation results for label detection.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L238","resources":[],"examples":[],"params":[{"name":"timeOffset","description":"<p> Time-offset, relative to the beginning of the video, corresponding to the  video frame for this location.</p><p> This object should have the same structure as google.protobuf.Duration</p>","types":["Object"],"optional":false,"nullable":false},{"name":"confidence","description":"<p> Confidence that the label is accurate. Range: [0, 1].</p>","types":["number"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"Entity","name":"Entity","type":"instance","description":"<p>Detected entity from video analysis.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L259","resources":[],"examples":[],"params":[{"name":"entityId","description":"<p> Opaque entity ID. Some IDs may be available in  <a href=\"https://developers.google.com/knowledge-graph/\">Google Knowledge Graph Search  API</a>.</p>","types":["string"],"optional":false,"nullable":false},{"name":"description","description":"<p> Textual description, e.g. <code>Fixed-gear bicycle</code>.</p>","types":["string"],"optional":false,"nullable":false},{"name":"languageCode","description":"<p> Language code for <code>description</code> in BCP-47 format.</p>","types":["string"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"LabelAnnotation","name":"LabelAnnotation","type":"instance","description":"<p>Label annotation.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L292","resources":[],"examples":[],"params":[{"name":"entity","description":"<p> Detected entity.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'Entity'\n        })\">Entity</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'Entity'\n        })\">Entity</a></p>","types":["Object"],"optional":false,"nullable":false},{"name":"categoryEntities","description":"<p> Common categories for the detected entity.  E.g. when the label is <code>Terrier</code> the category is likely <code>dog</code>. And in some  cases there might be more than one categories e.g. <code>Terrier</code> could also be  a <code>pet</code>.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'Entity'\n        })\">Entity</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'Entity'\n        })\">Entity</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"segments","description":"<p> All video segments where a label was detected.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'LabelSegment'\n        })\">LabelSegment</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'LabelSegment'\n        })\">LabelSegment</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"frames","description":"<p> All video frames where a label was detected.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'LabelFrame'\n        })\">LabelFrame</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'LabelFrame'\n        })\">LabelFrame</a></p>","types":["Object[]"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"ExplicitContentFrame","name":"ExplicitContentFrame","type":"instance","description":"<p>Video frame level annotation results for explicit content.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L313","resources":[],"examples":[],"params":[{"name":"timeOffset","description":"<p> Time-offset, relative to the beginning of the video, corresponding to the  video frame for this location.</p><p> This object should have the same structure as google.protobuf.Duration</p>","types":["Object"],"optional":false,"nullable":false},{"name":"pornographyLikelihood","description":"<p> Likelihood of the pornography content..</p><p> The number should be among the values of <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'Likelihood'\n        })\">Likelihood</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'Likelihood'\n        })\">Likelihood</a></p>","types":["number"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"ExplicitContentAnnotation","name":"ExplicitContentAnnotation","type":"instance","description":"<p>Explicit content annotation (based on per-frame visual signals only). If no explicit content has been detected in a frame, no annotations are present for that frame.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L330","resources":[],"examples":[],"params":[{"name":"frames","description":"<p> All video frames where explicit content was detected.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'ExplicitContentFrame'\n        })\">ExplicitContentFrame</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'ExplicitContentFrame'\n        })\">ExplicitContentFrame</a></p>","types":["Object[]"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"NormalizedBoundingBox","name":"NormalizedBoundingBox","type":"instance","description":"<p>Normalized bounding box. The normalized vertex coordinates are relative to the original image. Range: [0, 1].</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L354","resources":[],"examples":[],"params":[{"name":"left","description":"<p> Left X coordinate.</p>","types":["number"],"optional":false,"nullable":false},{"name":"top","description":"<p> Top Y coordinate.</p>","types":["number"],"optional":false,"nullable":false},{"name":"right","description":"<p> Right X coordinate.</p>","types":["number"],"optional":false,"nullable":false},{"name":"bottom","description":"<p> Bottom Y coordinate.</p>","types":["number"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"FaceSegment","name":"FaceSegment","type":"instance","description":"<p>Video segment level annotation results for face detection.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L369","resources":[],"examples":[],"params":[{"name":"segment","description":"<p> Video segment where a face was detected.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a></p>","types":["Object"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"FaceFrame","name":"FaceFrame","type":"instance","description":"<p>Video frame level annotation results for face detection.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L392","resources":[],"examples":[],"params":[{"name":"normalizedBoundingBoxes","description":"<p> Normalized Bounding boxes in a frame.  There can be more than one boxes if the same face is detected in multiple  locations within the current frame.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'NormalizedBoundingBox'\n        })\">NormalizedBoundingBox</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'NormalizedBoundingBox'\n        })\">NormalizedBoundingBox</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"timeOffset","description":"<p> Time-offset, relative to the beginning of the video,  corresponding to the video frame for this location.</p><p> This object should have the same structure as google.protobuf.Duration</p>","types":["Object"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"FaceAnnotation","name":"FaceAnnotation","type":"instance","description":"<p>Face annotation.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L415","resources":[],"examples":[],"params":[{"name":"thumbnail","description":"<p> Thumbnail of a representative face view (in JPEG format). Encoding: base64.</p>","types":["string"],"optional":false,"nullable":false},{"name":"segments","description":"<p> All video segments where a face was detected.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'FaceSegment'\n        })\">FaceSegment</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'FaceSegment'\n        })\">FaceSegment</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"frames","description":"<p> All video frames where a face was detected.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'FaceFrame'\n        })\">FaceFrame</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'FaceFrame'\n        })\">FaceFrame</a></p>","types":["Object[]"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"VideoAnnotationResults","name":"VideoAnnotationResults","type":"instance","description":"<p>Annotation results for a single video.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L468","resources":[],"examples":[],"params":[{"name":"inputUri","description":"<p> Video file location in  <a href=\"https://cloud.google.com/storage/\">Google Cloud Storage</a>.</p>","types":["string"],"optional":false,"nullable":false},{"name":"segmentLabelAnnotations","description":"<p> Label annotations on video level or user specified segment level.  There is exactly one element for each unique label.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'LabelAnnotation'\n        })\">LabelAnnotation</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'LabelAnnotation'\n        })\">LabelAnnotation</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"shotLabelAnnotations","description":"<p> Label annotations on shot level.  There is exactly one element for each unique label.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'LabelAnnotation'\n        })\">LabelAnnotation</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'LabelAnnotation'\n        })\">LabelAnnotation</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"frameLabelAnnotations","description":"<p> Label annotations on frame level.  There is exactly one element for each unique label.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'LabelAnnotation'\n        })\">LabelAnnotation</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'LabelAnnotation'\n        })\">LabelAnnotation</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"faceAnnotations","description":"<p> Face annotations. There is exactly one element for each unique face.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'FaceAnnotation'\n        })\">FaceAnnotation</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'FaceAnnotation'\n        })\">FaceAnnotation</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"shotAnnotations","description":"<p> Shot annotations. Each shot is represented as a video segment.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"explicitAnnotation","description":"<p> Explicit content annotation.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'ExplicitContentAnnotation'\n        })\">ExplicitContentAnnotation</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'ExplicitContentAnnotation'\n        })\">ExplicitContentAnnotation</a></p>","types":["Object"],"optional":false,"nullable":false},{"name":"error","description":"<p> If set, indicates an error. Note that for a single <code>AnnotateVideoRequest</code>  some videos may succeed and some may fail.</p><p> This object should have the same structure as google.rpc.Status</p>","types":["Object"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"AnnotateVideoResponse","name":"AnnotateVideoResponse","type":"instance","description":"","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L485","resources":[],"examples":[],"params":[{"name":"annotationResults","description":"<p> Annotation results for all videos specified in <code>AnnotateVideoRequest</code>.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoAnnotationResults'\n        })\">VideoAnnotationResults</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoAnnotationResults'\n        })\">VideoAnnotationResults</a></p>","types":["Object[]"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"VideoAnnotationProgress","name":"VideoAnnotationProgress","type":"instance","description":"<p>Annotation progress for a single video.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L513","resources":[],"examples":[],"params":[{"name":"inputUri","description":"<p> Video file location in  <a href=\"https://cloud.google.com/storage/\">Google Cloud Storage</a>.</p>","types":["string"],"optional":false,"nullable":false},{"name":"progressPercent","description":"<p> Approximate percentage processed thus far.  Guaranteed to be 100 when fully processed.</p>","types":["number"],"optional":false,"nullable":false},{"name":"startTime","description":"<p> Time when the request was received.</p><p> This object should have the same structure as google.protobuf.Timestamp</p>","types":["Object"],"optional":false,"nullable":false},{"name":"updateTime","description":"<p> Time of the most recent update.</p><p> This object should have the same structure as google.protobuf.Timestamp</p>","types":["Object"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"AnnotateVideoProgress","name":"AnnotateVideoProgress","type":"instance","description":"<p>Video annotation progress. Included in the <code>metadata</code> field of the <code>Operation</code> returned by the <code>GetOperation</code> call of the <code>google::longrunning::Operations</code> service.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L530","resources":[],"examples":[],"params":[{"name":"annotationProgress","description":"<p> Progress metadata for all videos specified in <code>AnnotateVideoRequest</code>.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoAnnotationProgress'\n        })\">VideoAnnotationProgress</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoAnnotationProgress'\n        })\">VideoAnnotationProgress</a></p>","types":["Object[]"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"Feature","name":"Feature","type":"instance","description":"<p>Video annotation feature.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L539","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"LabelDetectionMode","name":"LabelDetectionMode","type":"instance","description":"<p>Label detection mode.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L572","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"Likelihood","name":"Likelihood","type":"instance","description":"<p>Bucketized representation of likelihood.</p>","source":"packages\\video-intelligence\\src\\v1beta2\\doc\\doc_video_intelligence.js#L600","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]}],"path":"doc_video_intelligence.json"}