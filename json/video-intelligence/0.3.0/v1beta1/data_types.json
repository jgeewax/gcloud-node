{"name":"Data Types","methods":[{"type":"instance","description":"<p><code>Any</code> contains an arbitrary serialized protocol buffer message along with a URL that describes the type of the serialized message.</p><p>Protobuf library provides support to pack/unpack Any values in the form of utility functions or additional generated methods of the Any type.</p><p>Example 1: Pack and unpack a message in C++.</p><pre><code>Foo foo = ...; Any any; any.PackFrom(foo); ... if (any.UnpackTo(&amp;foo)) { ... } </code></pre><p>Example 2: Pack and unpack a message in Java.</p><pre><code>Foo foo = ...; Any any = Any.pack(foo); ... if (any.is(Foo.class)) { foo = any.unpack(Foo.class); } </code></pre><p> Example 3: Pack and unpack a message in Python.</p><pre><code>foo = Foo(...) any = Any() any.Pack(foo) ... if any.Is(Foo.DESCRIPTOR): any.Unpack(foo) ... </code></pre><p> Example 4: Pack and unpack a message in Go</p><pre><code> foo := &amp;pb.Foo{...} any, err := ptypes.MarshalAny(foo) ... foo := &amp;pb.Foo{} if err := ptypes.UnmarshalAny(any, foo); err != nil { ... } </code></pre><p>The pack methods provided by protobuf library will by default use &#39;type.googleapis.com/full.type.name&#39; as the type URL and the unpack methods only use the fully qualified type name after the last &#39;/&#39; in the type URL, for example &quot;foo.bar.com/x/y.z&quot; will yield type name &quot;y.z&quot;.</p><h1>JSON</h1> <p>The JSON representation of an <code>Any</code> value uses the regular representation of the deserialized, embedded message, with an additional field <code>@type</code> which contains the type URL. Example:</p><pre><code>package google.profile; message Person { string first_name = 1; string last_name = 2; } { &quot;@type&quot;: &quot;type.googleapis.com/google.profile.Person&quot;, &quot;firstName&quot;: &lt;string&gt;, &quot;lastName&quot;: &lt;string&gt; } </code></pre><p>If the embedded message type is well-known and has a custom JSON representation, that representation will be embedded adding a field <code>value</code> which holds the custom JSON in addition to the <code>@type</code> field. Example (for message {@link google.protobuf.Duration}):</p><pre><code>{ &quot;@type&quot;: &quot;type.googleapis.com/google.protobuf.Duration&quot;, &quot;value&quot;: &quot;1.212s&quot; } </code></pre>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_google_protobuf_any.js#L132","resources":[],"examples":[],"params":[{"name":"typeUrl","description":"<p> A URL/resource name whose content describes the type of the  serialized protocol buffer message.</p><p> For URLs which use the scheme <code>http</code>, <code>https</code>, or no scheme, the  following restrictions and interpretations apply:</p><ul> <li>If no scheme is provided, <code>https</code> is assumed.</li> <li>The last segment of the URL&#39;s path must represent the fully qualified name of the type (as in <code>path/google.protobuf.Duration</code>). The name should be in a canonical form (e.g., leading &quot;.&quot; is not accepted).</li> <li>An HTTP GET on the URL must yield a {@link google.protobuf.Type} value in binary format, or produce an error.</li> <li><p>Applications are allowed to cache lookup results based on the URL, or have them precompiled into a binary to avoid any lookup. Therefore, binary compatibility needs to be preserved on changes to types. (Use versioned type names to manage breaking changes.)</p><p>Schemes other than <code>http</code>, <code>https</code> (or the empty scheme) might be used with implementation specific semantics.</p></li> </ul> ","types":["string"],"optional":false,"nullable":false},{"name":"value","description":"<p> Must be a valid serialized protocol buffer of the above specified type.</p>","types":["string"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"type":"instance","description":"<p>The <code>Status</code> type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by <a href=\"https://github.com/grpc\">gRPC</a>. The error model is designed to be:</p><ul> <li>Simple to use and understand for most users</li> <li>Flexible enough to meet unexpected needs</li> </ul> <h1>Overview</h1> <p>The <code>Status</code> message contains three pieces of data: error code, error message, and error details. The error code should be an enum value of {@link google.rpc.Code}, but it may accept additional error codes if needed. The error message should be a developer-facing English message that helps developers <em>understand</em> and <em>resolve</em> the error. If a localized user-facing error message is needed, put the localized message in the error details or localize it in the client. The optional error details may contain arbitrary information about the error. There is a predefined set of error detail types in the package <code>google.rpc</code> that can be used for common error conditions.</p><h1>Language mapping</h1> <p>The <code>Status</code> message is the logical representation of the error model, but it is not necessarily the actual wire format. When the <code>Status</code> message is exposed in different client libraries and different wire protocols, it can be mapped differently. For example, it will likely be mapped to some exceptions in Java, but more likely mapped to some error codes in C.</p><h1>Other uses</h1> <p>The error model and the <code>Status</code> message can be used in a variety of environments, either with or without APIs, to provide a consistent developer experience across different environments.</p><p>Example uses of this error model include:</p><ul> <li><p>Partial errors. If a service needs to return partial errors to the client,  it may embed the <code>Status</code> in the normal response to indicate the partial  errors.</p></li> <li><p>Workflow errors. A typical workflow has multiple steps. Each step may  have a <code>Status</code> message for error reporting.</p></li> <li><p>Batch operations. If a client uses batch request and batch response, the  <code>Status</code> message should be used directly inside batch response, one for  each error sub-response.</p></li> <li><p>Asynchronous operations. If an API call embeds asynchronous operation  results in its response, the status of those operations should be  represented directly using the <code>Status</code> message.</p></li> <li><p>Logging. If some API errors are stored in logs, the message <code>Status</code> could  be used directly after any stripping needed for security/privacy reasons.</p></li> </ul> ","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_google_rpc_status.js#L93","resources":[],"examples":[],"params":[{"name":"code","description":"<p> The status code, which should be an enum value of {@link google.rpc.Code}.</p>","types":["number"],"optional":false,"nullable":false},{"name":"message","description":"<p> A developer-facing error message, which should be in English. Any  user-facing error message should be localized and sent in the  {@link google.rpc.Status.details} field, or localized by the client.</p>","types":["string"],"optional":false,"nullable":false},{"name":"details","description":"<p> A list of messages that carry the error details. There is a common set of  message types for APIs to use.</p><p> This object should have the same structure as google.protobuf.Any</p>","types":["Object[]"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"AnnotateVideoRequest","name":"AnnotateVideoRequest","type":"instance","description":"","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L67","resources":[],"examples":[],"params":[{"name":"inputUri","description":"<p> Input video location. Currently, only  <a href=\"https://cloud.google.com/storage/\">Google Cloud Storage</a> URIs are  supported, which must be specified in the following format:  <code>gs://bucket-id/object-id</code> (other URI formats return  {@link google.rpc.Code.INVALID_ARGUMENT}). For more information, see  <a href=\"https://cloud.google.com/storage/docs/reference-uris\">Request URIs</a>.  A video URI may include wildcards in <code>object-id</code>, and thus identify  multiple videos. Supported wildcards: &#39;*&#39; to match 0 or more characters;  &#39;?&#39; to match 1 character. If unset, the input video should be embedded  in the request as <code>input_content</code>. If set, <code>input_content</code> should be unset.</p>","types":["string"],"optional":false,"nullable":false},{"name":"inputContent","description":"<p> The video data bytes. Encoding: base64. If unset, the input video(s)  should be specified via <code>input_uri</code>. If set, <code>input_uri</code> should be unset.</p>","types":["string"],"optional":false,"nullable":false},{"name":"features","description":"<p> Requested video annotation features.</p><p> The number should be among the values of <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'Feature'\n        })\">Feature</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'Feature'\n        })\">Feature</a></p>","types":["number[]"],"optional":false,"nullable":false},{"name":"videoContext","description":"<p> Additional video context and/or feature-specific parameters.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoContext'\n        })\">VideoContext</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoContext'\n        })\">VideoContext</a></p>","types":["Object"],"optional":false,"nullable":false},{"name":"outputUri","description":"<p> Optional location where the output (in JSON format) should be stored.  Currently, only <a href=\"https://cloud.google.com/storage/\">Google Cloud Storage</a>  URIs are supported, which must be specified in the following format:  <code>gs://bucket-id/object-id</code> (other URI formats return  {@link google.rpc.Code.INVALID_ARGUMENT}). For more information, see  <a href=\"https://cloud.google.com/storage/docs/reference-uris\">Request URIs</a>.</p>","types":["string"],"optional":false,"nullable":false},{"name":"locationId","description":"<p> Optional cloud region where annotation should take place. Supported cloud  regions: <code>us-east1</code>, <code>us-west1</code>, <code>europe-west1</code>, <code>asia-east1</code>. If no region  is specified, a region will be determined based on video file location.</p>","types":["string"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"VideoContext","name":"VideoContext","type":"instance","description":"<p>Video context and/or feature-specific parameters.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L111","resources":[],"examples":[],"params":[{"name":"segments","description":"<p> Video segments to annotate. The segments may overlap and are not required  to be contiguous or span the whole video. If unspecified, each video  is treated as a single segment.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"labelDetectionMode","description":"<p> If label detection has been requested, what labels should be detected  in addition to video-level labels or segment-level labels. If unspecified,  defaults to <code>SHOT_MODE</code>.</p><p> The number should be among the values of <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'LabelDetectionMode'\n        })\">LabelDetectionMode</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'LabelDetectionMode'\n        })\">LabelDetectionMode</a></p>","types":["number"],"optional":false,"nullable":false},{"name":"stationaryCamera","description":"<p> Whether the video has been shot from a stationary (i.e. non-moving) camera.  When set to true, might improve detection accuracy for moving objects.</p>","types":["boolean"],"optional":false,"nullable":false},{"name":"labelDetectionModel","description":"<p> Model to use for label detection.  Supported values: &quot;latest&quot; and &quot;stable&quot; (the default).</p>","types":["string"],"optional":false,"nullable":false},{"name":"faceDetectionModel","description":"<p> Model to use for face detection.  Supported values: &quot;latest&quot; and &quot;stable&quot; (the default).</p>","types":["string"],"optional":false,"nullable":false},{"name":"shotChangeDetectionModel","description":"<p> Model to use for shot change detection.  Supported values: &quot;latest&quot; and &quot;stable&quot; (the default).</p>","types":["string"],"optional":false,"nullable":false},{"name":"safeSearchDetectionModel","description":"<p> Model to use for safe search detection.  Supported values: &quot;latest&quot; and &quot;stable&quot; (the default).</p>","types":["string"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"VideoSegment","name":"VideoSegment","type":"instance","description":"<p>Video segment.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L127","resources":[],"examples":[],"params":[{"name":"startTimeOffset","description":"<p> Start offset in microseconds (inclusive). Unset means 0.</p>","types":["number"],"optional":false,"nullable":false},{"name":"endTimeOffset","description":"<p> End offset in microseconds (inclusive). Unset means 0.</p>","types":["number"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"LabelLocation","name":"LabelLocation","type":"instance","description":"<p>Label location.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L153","resources":[],"examples":[],"params":[{"name":"segment","description":"<p> Video segment. Set to [-1, -1] for video-level labels.  Set to [timestamp, timestamp] for frame-level labels.  Otherwise, corresponds to one of <code>AnnotateSpec.segments</code>  (if specified) or to shot boundaries (if requested).</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a></p>","types":["Object"],"optional":false,"nullable":false},{"name":"confidence","description":"<p> Confidence that the label is accurate. Range: [0, 1].</p>","types":["number"],"optional":false,"nullable":false},{"name":"level","description":"<p> Label level.</p><p> The number should be among the values of <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'LabelLevel'\n        })\">LabelLevel</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'LabelLevel'\n        })\">LabelLevel</a></p>","types":["number"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"LabelAnnotation","name":"LabelAnnotation","type":"instance","description":"<p>Label annotation.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L174","resources":[],"examples":[],"params":[{"name":"description","description":"<p> Textual description, e.g. <code>Fixed-gear bicycle</code>.</p>","types":["string"],"optional":false,"nullable":false},{"name":"languageCode","description":"<p> Language code for <code>description</code> in BCP-47 format.</p>","types":["string"],"optional":false,"nullable":false},{"name":"locations","description":"<p> Where the label was detected and with what confidence.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'LabelLocation'\n        })\">LabelLocation</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'LabelLocation'\n        })\">LabelLocation</a></p>","types":["Object[]"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"SafeSearchAnnotation","name":"SafeSearchAnnotation","type":"instance","description":"<p>Safe search annotation (based on per-frame visual signals only). If no unsafe content has been detected in a frame, no annotations are present for that frame. If only some types of unsafe content have been detected in a frame, the likelihood is set to <code>UNKNOWN</code> for all other types of unsafe content.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L217","resources":[],"examples":[],"params":[{"name":"adult","description":"<p> Likelihood of adult content.</p><p> The number should be among the values of <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'Likelihood'\n        })\">Likelihood</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'Likelihood'\n        })\">Likelihood</a></p>","types":["number"],"optional":false,"nullable":false},{"name":"spoof","description":"<p> Likelihood that an obvious modification was made to the original  version to make it appear funny or offensive.</p><p> The number should be among the values of <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'Likelihood'\n        })\">Likelihood</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'Likelihood'\n        })\">Likelihood</a></p>","types":["number"],"optional":false,"nullable":false},{"name":"medical","description":"<p> Likelihood of medical content.</p><p> The number should be among the values of <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'Likelihood'\n        })\">Likelihood</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'Likelihood'\n        })\">Likelihood</a></p>","types":["number"],"optional":false,"nullable":false},{"name":"violent","description":"<p> Likelihood of violent content.</p><p> The number should be among the values of <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'Likelihood'\n        })\">Likelihood</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'Likelihood'\n        })\">Likelihood</a></p>","types":["number"],"optional":false,"nullable":false},{"name":"racy","description":"<p> Likelihood of racy content.</p><p> The number should be among the values of <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'Likelihood'\n        })\">Likelihood</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'Likelihood'\n        })\">Likelihood</a></p>","types":["number"],"optional":false,"nullable":false},{"name":"timeOffset","description":"<p> Video time offset in microseconds.</p>","types":["number"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"BoundingBox","name":"BoundingBox","type":"instance","description":"<p>Bounding box.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L239","resources":[],"examples":[],"params":[{"name":"left","description":"<p> Left X coordinate.</p>","types":["number"],"optional":false,"nullable":false},{"name":"right","description":"<p> Right X coordinate.</p>","types":["number"],"optional":false,"nullable":false},{"name":"bottom","description":"<p> Bottom Y coordinate.</p>","types":["number"],"optional":false,"nullable":false},{"name":"top","description":"<p> Top Y coordinate.</p>","types":["number"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"FaceLocation","name":"FaceLocation","type":"instance","description":"<p>Face location.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L257","resources":[],"examples":[],"params":[{"name":"boundingBox","description":"<p> Bounding box in a frame.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'BoundingBox'\n        })\">BoundingBox</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'BoundingBox'\n        })\">BoundingBox</a></p>","types":["Object"],"optional":false,"nullable":false},{"name":"timeOffset","description":"<p> Video time offset in microseconds.</p>","types":["number"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"FaceAnnotation","name":"FaceAnnotation","type":"instance","description":"<p>Face annotation.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L282","resources":[],"examples":[],"params":[{"name":"thumbnail","description":"<p> Thumbnail of a representative face view (in JPEG format). Encoding: base64.</p>","types":["string"],"optional":false,"nullable":false},{"name":"segments","description":"<p> All locations where a face was detected.  Faces are detected and tracked on a per-video basis  (as opposed to across multiple videos).</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"locations","description":"<p> Face locations at one frame per second.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'FaceLocation'\n        })\">FaceLocation</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'FaceLocation'\n        })\">FaceLocation</a></p>","types":["Object[]"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"VideoAnnotationResults","name":"VideoAnnotationResults","type":"instance","description":"<p>Annotation results for a single video.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L322","resources":[],"examples":[],"params":[{"name":"inputUri","description":"<p> Video file location in  <a href=\"https://cloud.google.com/storage/\">Google Cloud Storage</a>.</p>","types":["string"],"optional":false,"nullable":false},{"name":"labelAnnotations","description":"<p> Label annotations. There is exactly one element for each unique label.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'LabelAnnotation'\n        })\">LabelAnnotation</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'LabelAnnotation'\n        })\">LabelAnnotation</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"faceAnnotations","description":"<p> Face annotations. There is exactly one element for each unique face.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'FaceAnnotation'\n        })\">FaceAnnotation</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'FaceAnnotation'\n        })\">FaceAnnotation</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"shotAnnotations","description":"<p> Shot annotations. Each shot is represented as a video segment.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoSegment'\n        })\">VideoSegment</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"safeSearchAnnotations","description":"<p> Safe search annotations.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'SafeSearchAnnotation'\n        })\">SafeSearchAnnotation</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'SafeSearchAnnotation'\n        })\">SafeSearchAnnotation</a></p>","types":["Object[]"],"optional":false,"nullable":false},{"name":"error","description":"<p> If set, indicates an error. Note that for a single <code>AnnotateVideoRequest</code>  some videos may succeed and some may fail.</p><p> This object should have the same structure as google.rpc.Status</p>","types":["Object"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"AnnotateVideoResponse","name":"AnnotateVideoResponse","type":"instance","description":"","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L339","resources":[],"examples":[],"params":[{"name":"annotationResults","description":"<p> Annotation results for all videos specified in <code>AnnotateVideoRequest</code>.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoAnnotationResults'\n        })\">VideoAnnotationResults</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoAnnotationResults'\n        })\">VideoAnnotationResults</a></p>","types":["Object[]"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"VideoAnnotationProgress","name":"VideoAnnotationProgress","type":"instance","description":"<p>Annotation progress for a single video.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L367","resources":[],"examples":[],"params":[{"name":"inputUri","description":"<p> Video file location in  <a href=\"https://cloud.google.com/storage/\">Google Cloud Storage</a>.</p>","types":["string"],"optional":false,"nullable":false},{"name":"progressPercent","description":"<p> Approximate percentage processed thus far.  Guaranteed to be 100 when fully processed.</p>","types":["number"],"optional":false,"nullable":false},{"name":"startTime","description":"<p> Time when the request was received.</p><p> This object should have the same structure as google.protobuf.Timestamp</p>","types":["Object"],"optional":false,"nullable":false},{"name":"updateTime","description":"<p> Time of the most recent update.</p><p> This object should have the same structure as google.protobuf.Timestamp</p>","types":["Object"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"AnnotateVideoProgress","name":"AnnotateVideoProgress","type":"instance","description":"<p>Video annotation progress. Included in the <code>metadata</code> field of the <code>Operation</code> returned by the <code>GetOperation</code> call of the <code>google::longrunning::Operations</code> service.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L384","resources":[],"examples":[],"params":[{"name":"annotationProgress","description":"<p> Progress metadata for all videos specified in <code>AnnotateVideoRequest</code>.</p><p> This object should have the same structure as <a ng-if=\"service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.parent}}/{{service.path.split('/').shift()}}/data_types',\n          method: 'VideoAnnotationProgress'\n        })\">VideoAnnotationProgress</a>\n\n        <a ng-if=\"!service.parent\" ui-sref=\"docs.service({\n          serviceId: '{{service.title.split('V')[0] + '/v' + service.title.split('V')[1]}}/data_types',\n          method: 'VideoAnnotationProgress'\n        })\">VideoAnnotationProgress</a></p>","types":["Object[]"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"Feature","name":"Feature","type":"instance","description":"<p>Video annotation feature.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L393","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"LabelLevel","name":"LabelLevel","type":"instance","description":"<p>Label level (scope).</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L426","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"LabelDetectionMode","name":"LabelDetectionMode","type":"instance","description":"<p>Label detection mode.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L460","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"Likelihood","name":"Likelihood","type":"instance","description":"<p>Bucketized representation of likelihood.</p>","source":"packages\\video-intelligence\\src\\v1beta1\\doc\\doc_video_intelligence.js#L488","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]}],"path":"v1beta1/data_types.json","description":"\n          <table class=\"table\">\n            <thead>\n              <tr>\n                <th>Class</th>\n                <th>Description</th>\n              </tr>\n            </thead>\n            <tbody>\n              <tr ng-repeat=\"method in service.methods\" ng-if=\"method.name\">\n                <td>\n                  <a ui-sref=\"docs.service({ method: method.id })\" class=\"skip-external-link\">\n                    {{method.name}}\n                  </a>\n                </td>\n                <td>\n                  <span ng-bind-html=\"method.description\">\n                    {{method.description}}\n                  </span>\n                  <span ng-if=\"!method.description && method.name.includes('Request')\">\n                    The request for {{method.name}}.\n                  </span>\n                  <span ng-if=\"!method.description && method.name.includes('Response')\">\n                    The response for {{method.name}}.\n                  </span>\n                </td>\n              </tr>\n            </tbody>\n          </table>\n        ","id":"video-intelligence/v1beta1/data_types"}